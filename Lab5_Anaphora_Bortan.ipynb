{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anaphora resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import functional as F\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File gap-development.tsv does not exist: 'gap-development.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e666702aa158>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_dev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gap-development.tsv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File gap-development.tsv does not exist: 'gap-development.tsv'"
     ]
    }
   ],
   "source": [
    "df_dev = pd.read_csv('gap-development.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Pronoun-offset</th>\n",
       "      <th>A</th>\n",
       "      <th>A-offset</th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B</th>\n",
       "      <th>B-offset</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>development-1</td>\n",
       "      <td>Zoe Telford -- played the police officer girlf...</td>\n",
       "      <td>her</td>\n",
       "      <td>274</td>\n",
       "      <td>Cheryl Cassidy</td>\n",
       "      <td>191</td>\n",
       "      <td>True</td>\n",
       "      <td>Pauline</td>\n",
       "      <td>207</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/List_of_Teachers_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>development-2</td>\n",
       "      <td>He grew up in Evanston, Illinois the second ol...</td>\n",
       "      <td>His</td>\n",
       "      <td>284</td>\n",
       "      <td>MacKenzie</td>\n",
       "      <td>228</td>\n",
       "      <td>True</td>\n",
       "      <td>Bernard Leach</td>\n",
       "      <td>251</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Warren_MacKenzie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>development-3</td>\n",
       "      <td>He had been reelected to Congress, but resigne...</td>\n",
       "      <td>his</td>\n",
       "      <td>265</td>\n",
       "      <td>Angeloz</td>\n",
       "      <td>173</td>\n",
       "      <td>False</td>\n",
       "      <td>De la Sota</td>\n",
       "      <td>246</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jos%C3%A9_Manuel_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>development-4</td>\n",
       "      <td>The current members of Crime have also perform...</td>\n",
       "      <td>his</td>\n",
       "      <td>321</td>\n",
       "      <td>Hell</td>\n",
       "      <td>174</td>\n",
       "      <td>False</td>\n",
       "      <td>Henry Rosenthal</td>\n",
       "      <td>336</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Crime_(band)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>development-5</td>\n",
       "      <td>Her Santa Fe Opera debut in 2005 was as Nuria ...</td>\n",
       "      <td>She</td>\n",
       "      <td>437</td>\n",
       "      <td>Kitty Oppenheimer</td>\n",
       "      <td>219</td>\n",
       "      <td>False</td>\n",
       "      <td>Rivera</td>\n",
       "      <td>294</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jessica_Rivera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>development-1996</td>\n",
       "      <td>Faye's third husband, Paul Resnick, reported t...</td>\n",
       "      <td>her</td>\n",
       "      <td>433</td>\n",
       "      <td>Nicole</td>\n",
       "      <td>255</td>\n",
       "      <td>False</td>\n",
       "      <td>Faye</td>\n",
       "      <td>328</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Faye_Resnick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>development-1997</td>\n",
       "      <td>The plot of the film focuses on the life of a ...</td>\n",
       "      <td>her</td>\n",
       "      <td>246</td>\n",
       "      <td>Doris Chu</td>\n",
       "      <td>111</td>\n",
       "      <td>False</td>\n",
       "      <td>Mei</td>\n",
       "      <td>215</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Two_Lies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>development-1998</td>\n",
       "      <td>Grant played the part in Trevor Nunn's movie a...</td>\n",
       "      <td>she</td>\n",
       "      <td>348</td>\n",
       "      <td>Maria</td>\n",
       "      <td>259</td>\n",
       "      <td>True</td>\n",
       "      <td>Imelda Staunton</td>\n",
       "      <td>266</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Sir_Andrew_Aguecheek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>development-1999</td>\n",
       "      <td>The fashion house specialised in hand-printed ...</td>\n",
       "      <td>She</td>\n",
       "      <td>284</td>\n",
       "      <td>Helen</td>\n",
       "      <td>145</td>\n",
       "      <td>True</td>\n",
       "      <td>Suzanne Bartsch</td>\n",
       "      <td>208</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Helen_David</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>development-2000</td>\n",
       "      <td>Watkins was a close friend of Hess' first wife...</td>\n",
       "      <td>her</td>\n",
       "      <td>373</td>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>293</td>\n",
       "      <td>False</td>\n",
       "      <td>Watkins</td>\n",
       "      <td>347</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Linda_Watkins</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                                               Text  \\\n",
       "0        development-1  Zoe Telford -- played the police officer girlf...   \n",
       "1        development-2  He grew up in Evanston, Illinois the second ol...   \n",
       "2        development-3  He had been reelected to Congress, but resigne...   \n",
       "3        development-4  The current members of Crime have also perform...   \n",
       "4        development-5  Her Santa Fe Opera debut in 2005 was as Nuria ...   \n",
       "...                ...                                                ...   \n",
       "1995  development-1996  Faye's third husband, Paul Resnick, reported t...   \n",
       "1996  development-1997  The plot of the film focuses on the life of a ...   \n",
       "1997  development-1998  Grant played the part in Trevor Nunn's movie a...   \n",
       "1998  development-1999  The fashion house specialised in hand-printed ...   \n",
       "1999  development-2000  Watkins was a close friend of Hess' first wife...   \n",
       "\n",
       "     Pronoun  Pronoun-offset                  A  A-offset  A-coref  \\\n",
       "0        her             274     Cheryl Cassidy       191     True   \n",
       "1        His             284          MacKenzie       228     True   \n",
       "2        his             265            Angeloz       173    False   \n",
       "3        his             321               Hell       174    False   \n",
       "4        She             437  Kitty Oppenheimer       219    False   \n",
       "...      ...             ...                ...       ...      ...   \n",
       "1995     her             433             Nicole       255    False   \n",
       "1996     her             246          Doris Chu       111    False   \n",
       "1997     she             348              Maria       259     True   \n",
       "1998     She             284              Helen       145     True   \n",
       "1999     her             373          Elizabeth       293    False   \n",
       "\n",
       "                    B  B-offset  B-coref  \\\n",
       "0             Pauline       207    False   \n",
       "1       Bernard Leach       251    False   \n",
       "2          De la Sota       246     True   \n",
       "3     Henry Rosenthal       336     True   \n",
       "4              Rivera       294     True   \n",
       "...               ...       ...      ...   \n",
       "1995             Faye       328     True   \n",
       "1996              Mei       215     True   \n",
       "1997  Imelda Staunton       266    False   \n",
       "1998  Suzanne Bartsch       208    False   \n",
       "1999          Watkins       347     True   \n",
       "\n",
       "                                                    URL  \n",
       "0     http://en.wikipedia.org/wiki/List_of_Teachers_...  \n",
       "1         http://en.wikipedia.org/wiki/Warren_MacKenzie  \n",
       "2     http://en.wikipedia.org/wiki/Jos%C3%A9_Manuel_...  \n",
       "3             http://en.wikipedia.org/wiki/Crime_(band)  \n",
       "4           http://en.wikipedia.org/wiki/Jessica_Rivera  \n",
       "...                                                 ...  \n",
       "1995          http://en.wikipedia.org/wiki/Faye_Resnick  \n",
       "1996              http://en.wikipedia.org/wiki/Two_Lies  \n",
       "1997  http://en.wikipedia.org/wiki/Sir_Andrew_Aguecheek  \n",
       "1998           http://en.wikipedia.org/wiki/Helen_David  \n",
       "1999         http://en.wikipedia.org/wiki/Linda_Watkins  \n",
       "\n",
       "[2000 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_csv('gap-validation.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Pronoun-offset</th>\n",
       "      <th>A</th>\n",
       "      <th>A-offset</th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B</th>\n",
       "      <th>B-offset</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>validation-1</td>\n",
       "      <td>He admitted making four trips to China and pla...</td>\n",
       "      <td>him</td>\n",
       "      <td>256</td>\n",
       "      <td>Jose de Venecia Jr</td>\n",
       "      <td>208</td>\n",
       "      <td>False</td>\n",
       "      <td>Abalos</td>\n",
       "      <td>241</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Commission_on_Ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>validation-2</td>\n",
       "      <td>Kathleen Nott was born in Camberwell, London. ...</td>\n",
       "      <td>She</td>\n",
       "      <td>185</td>\n",
       "      <td>Ellen</td>\n",
       "      <td>110</td>\n",
       "      <td>False</td>\n",
       "      <td>Kathleen</td>\n",
       "      <td>150</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Kathleen_Nott</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>validation-3</td>\n",
       "      <td>When she returns to her hotel room, a Liberian...</td>\n",
       "      <td>his</td>\n",
       "      <td>435</td>\n",
       "      <td>Jason Scott Lee</td>\n",
       "      <td>383</td>\n",
       "      <td>False</td>\n",
       "      <td>Danny</td>\n",
       "      <td>406</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Hawaii_Five-0_(20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>validation-4</td>\n",
       "      <td>On 19 March 2007, during a campaign appearance...</td>\n",
       "      <td>he</td>\n",
       "      <td>333</td>\n",
       "      <td>Reucassel</td>\n",
       "      <td>300</td>\n",
       "      <td>True</td>\n",
       "      <td>Debnam</td>\n",
       "      <td>325</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Craig_Reucassel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>validation-5</td>\n",
       "      <td>By this time, Karen Blixen had separated from ...</td>\n",
       "      <td>she</td>\n",
       "      <td>427</td>\n",
       "      <td>Finch Hatton</td>\n",
       "      <td>290</td>\n",
       "      <td>False</td>\n",
       "      <td>Beryl Markham</td>\n",
       "      <td>328</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Denys_Finch_Hatton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>validation-450</td>\n",
       "      <td>He then agrees to name the gargoyle Goldie, af...</td>\n",
       "      <td>He</td>\n",
       "      <td>305</td>\n",
       "      <td>Lucien</td>\n",
       "      <td>252</td>\n",
       "      <td>False</td>\n",
       "      <td>Abel</td>\n",
       "      <td>264</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Goldie_(DC_Comics)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>validation-451</td>\n",
       "      <td>Disgusted with the family's ``mendacity'', Bri...</td>\n",
       "      <td>she</td>\n",
       "      <td>365</td>\n",
       "      <td>Maggie</td>\n",
       "      <td>242</td>\n",
       "      <td>False</td>\n",
       "      <td>Mae</td>\n",
       "      <td>257</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Cat_on_a_Hot_Tin_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>validation-452</td>\n",
       "      <td>She manipulates Michael into giving her custod...</td>\n",
       "      <td>she</td>\n",
       "      <td>306</td>\n",
       "      <td>Scarlett</td>\n",
       "      <td>255</td>\n",
       "      <td>False</td>\n",
       "      <td>Alice</td>\n",
       "      <td>291</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Michael_Moon_(Eas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>validation-453</td>\n",
       "      <td>On April 4, 1986, Donal Henahan wrote in the N...</td>\n",
       "      <td>her</td>\n",
       "      <td>330</td>\n",
       "      <td>Aida</td>\n",
       "      <td>250</td>\n",
       "      <td>False</td>\n",
       "      <td>Miss Millo</td>\n",
       "      <td>294</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Aprile_Millo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>validation-454</td>\n",
       "      <td>Pleasant explains Vassey's guilty conscience m...</td>\n",
       "      <td>him</td>\n",
       "      <td>282</td>\n",
       "      <td>Vassey</td>\n",
       "      <td>234</td>\n",
       "      <td>True</td>\n",
       "      <td>Denton</td>\n",
       "      <td>255</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Small_Crimes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>454 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID                                               Text  \\\n",
       "0      validation-1  He admitted making four trips to China and pla...   \n",
       "1      validation-2  Kathleen Nott was born in Camberwell, London. ...   \n",
       "2      validation-3  When she returns to her hotel room, a Liberian...   \n",
       "3      validation-4  On 19 March 2007, during a campaign appearance...   \n",
       "4      validation-5  By this time, Karen Blixen had separated from ...   \n",
       "..              ...                                                ...   \n",
       "449  validation-450  He then agrees to name the gargoyle Goldie, af...   \n",
       "450  validation-451  Disgusted with the family's ``mendacity'', Bri...   \n",
       "451  validation-452  She manipulates Michael into giving her custod...   \n",
       "452  validation-453  On April 4, 1986, Donal Henahan wrote in the N...   \n",
       "453  validation-454  Pleasant explains Vassey's guilty conscience m...   \n",
       "\n",
       "    Pronoun  Pronoun-offset                   A  A-offset  A-coref  \\\n",
       "0       him             256  Jose de Venecia Jr       208    False   \n",
       "1       She             185               Ellen       110    False   \n",
       "2       his             435     Jason Scott Lee       383    False   \n",
       "3        he             333           Reucassel       300     True   \n",
       "4       she             427        Finch Hatton       290    False   \n",
       "..      ...             ...                 ...       ...      ...   \n",
       "449      He             305              Lucien       252    False   \n",
       "450     she             365              Maggie       242    False   \n",
       "451     she             306            Scarlett       255    False   \n",
       "452     her             330                Aida       250    False   \n",
       "453     him             282              Vassey       234     True   \n",
       "\n",
       "                 B  B-offset  B-coref  \\\n",
       "0           Abalos       241    False   \n",
       "1         Kathleen       150     True   \n",
       "2            Danny       406     True   \n",
       "3           Debnam       325    False   \n",
       "4    Beryl Markham       328     True   \n",
       "..             ...       ...      ...   \n",
       "449           Abel       264    False   \n",
       "450            Mae       257    False   \n",
       "451          Alice       291     True   \n",
       "452     Miss Millo       294     True   \n",
       "453         Denton       255    False   \n",
       "\n",
       "                                                   URL  \n",
       "0    http://en.wikipedia.org/wiki/Commission_on_Ele...  \n",
       "1           http://en.wikipedia.org/wiki/Kathleen_Nott  \n",
       "2    http://en.wikipedia.org/wiki/Hawaii_Five-0_(20...  \n",
       "3         http://en.wikipedia.org/wiki/Craig_Reucassel  \n",
       "4      http://en.wikipedia.org/wiki/Denys_Finch_Hatton  \n",
       "..                                                 ...  \n",
       "449    http://en.wikipedia.org/wiki/Goldie_(DC_Comics)  \n",
       "450  http://en.wikipedia.org/wiki/Cat_on_a_Hot_Tin_...  \n",
       "451  http://en.wikipedia.org/wiki/Michael_Moon_(Eas...  \n",
       "452          http://en.wikipedia.org/wiki/Aprile_Millo  \n",
       "453          http://en.wikipedia.org/wiki/Small_Crimes  \n",
       "\n",
       "[454 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Creating the model\n",
    "## Takes a lot of time depending on the vector file size \n",
    "en_model = KeyedVectors.load_word2vec_format('wiki-news-300d-1M.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'*'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_model.index2word[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyAnaphoraNetwork(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=600, out_features=300, bias=True)\n",
      "    (1): Dropout(p=0.3, inplace=False)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=300, out_features=80, bias=True)\n",
      "    (4): Dropout(p=0.2, inplace=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=80, out_features=2, bias=True)\n",
      "    (7): Dropout(p=0.1, inplace=False)\n",
      "    (8): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyAnaphoraNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # define the layers\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(600, 300),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(300, 80),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 2),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # forward pass\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "# instantiate the model\n",
    "anmodel = MyAnaphoraNetwork()\n",
    "\n",
    "# print model architecture\n",
    "print(anmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Arbuzik/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "from nltk import tokenize\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = stopwords.words('english')\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\n|\\r', ' ', text)\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    text = tokenize.word_tokenize(text)\n",
    "    # Remove a sentence if it is only one word long\n",
    "    if len(text) > 2:\n",
    "        return [word for word in text if word not in STOPWORDS]\n",
    "    return text\n",
    "\n",
    "def simple_tokenizer(text, pronoun, candidate_a, candidate_b):\n",
    "    \n",
    "    \n",
    "    \n",
    "    toktxt = clean_text(text)\n",
    "    txt = []\n",
    "    txt.append(pronoun)\n",
    "    txt.append(candidate_a)\n",
    "    txt.append(candidate_b)\n",
    "    \n",
    "    txt = txt + toktxt\n",
    "    \n",
    "    tokenized_text = []\n",
    "    \n",
    "    for word in txt:\n",
    "        try:\n",
    "            word_index = en_model.wv.vocab[word].index\n",
    "            tokenized_text.append(word_index)\n",
    "        except KeyError:\n",
    "            tokenized_text.append(16)\n",
    "            \n",
    "    while len(tokenized_text) < 600:\n",
    "        tokenized_text.append(0)\n",
    "    vec = torch.Tensor([tokenized_text])\n",
    "    \n",
    "    return vec.view(1, -1)\n",
    "\n",
    "\n",
    "\n",
    "def make_target(label, label_to_ix):\n",
    "    #print(label_to_ix[str(label['A'])])\n",
    "    #print([label_to_ix[str(label['A'])], label_to_ix[str(label['B'])] ] )\n",
    "    return torch.LongTensor([[ label_to_ix[str(label['A'])], label_to_ix[str(label['B'])] ]])\n",
    "\n",
    "def decode_target(pred, label_to_ix):\n",
    "        pass\n",
    "\n",
    "label_to_ix = {\"True\": 1, \"False\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfMatrix():\n",
    "    def __init__(self):\n",
    "        self.true_positive = 0\n",
    "        self.false_positive = 0\n",
    "        self.true_negative = 0\n",
    "        self.false_negative = 0\n",
    "    \n",
    "    def precision(self):\n",
    "        pr = 0\n",
    "        if (self.true_positive + self.false_positive) != 0:\n",
    "            pr = self.true_positive / (self.true_positive + self.false_positive)\n",
    "        return round(pr * 100, 2) \n",
    "    \n",
    "    def recall(self):\n",
    "        rec = 0\n",
    "        if (self.true_positive - self.false_negative) != 0:\n",
    "            rec = self.true_positive / (self.true_positive + self.false_negative)\n",
    "        return round(rec * 100, 2) \n",
    "    \n",
    "    def f1_measure(self):\n",
    "        pr = self.precision()\n",
    "        rec = self.recall()\n",
    "        f1m = 0\n",
    "        if (pr + rec) != 0:\n",
    "            f1m = 2 * (pr * rec) / (pr + rec)\n",
    "        return round(f1m, 2)\n",
    "    \n",
    "    def accuracy(self):\n",
    "        acc = 0\n",
    "        if (self.true_positive + self.true_negative + self.false_positive + self.false_negative) != 0:\n",
    "            acc = (self.true_positive + self.true_negative) / (self.true_positive + self.true_negative + self.false_positive + self.false_negative)\n",
    "        return round(acc *100, 2)\n",
    "    \n",
    "    def compare_row(self, predicted, target):\n",
    "        \n",
    "        if predicted >= 1 and target >= 1:\n",
    "            self.true_positive += 1 \n",
    "            #print('predicted', predicted)\n",
    "            #print('target', target)\n",
    "            #print()\n",
    "        elif predicted == 0 and target == 0:\n",
    "            self.true_negative += 1\n",
    "        elif predicted >= 1 and target == 0:\n",
    "            self.false_positive += 1\n",
    "        elif predicted == 0 and target >= 1:\n",
    "            self.false_negative += 1\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"TN: {0}, FP: {1}, FN: {2}, TP: {3}, precision: {4}, recall: {5}, f1: {6} \\n\".format(self.true_negative, \n",
    "                                            self.false_positive, \n",
    "                                            self.false_negative, \n",
    "                                            self.true_positive,\n",
    "                                            self.precision(),\n",
    "                                            self.recall(),\n",
    "                                            self.f1_measure(),\n",
    "                                           \n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"TN: {0}, FP: {1}, FN: {2}, TP: {3}, precision: {4}, recall: {5}, f1: {6} \\n\".format(self.true_negative, \n",
    "                                            self.false_positive, \n",
    "                                            self.false_negative, \n",
    "                                            self.true_positive,\n",
    "                                            self.precision(),\n",
    "                                            self.recall(),\n",
    "                                            self.f1_measure(),\n",
    "                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TN: 0, FP: 0, FN: 0, TP: 0, precision: 0, recall: 0, f1: 0 "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_conmat = ConfMatrix()\n",
    "b_conmat = ConfMatrix()\n",
    "a_conmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Arbuzik/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:36: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_CM: TN: 1029, FP: 97, FN: 805, TP: 69, precision: 41.57, recall: 7.89, f1: 13.26 \n",
      "\n",
      "\n",
      "b_CM: TN: 1075, FP: 0, FN: 925, TP: 0, precision: 0, recall: 0.0, f1: 0 \n",
      "\n",
      "\n",
      "Epoch: 1\n",
      "\n",
      "a_CM: TN: 1056, FP: 70, FN: 808, TP: 66, precision: 48.53, recall: 7.55, f1: 13.07 \n",
      "\n",
      "\n",
      "b_CM: TN: 1075, FP: 0, FN: 925, TP: 0, precision: 0, recall: 0.0, f1: 0 \n",
      "\n",
      "\n",
      "Epoch: 2\n",
      "\n",
      "a_CM: TN: 1037, FP: 89, FN: 816, TP: 58, precision: 39.46, recall: 6.64, f1: 11.37 \n",
      "\n",
      "\n",
      "b_CM: TN: 1075, FP: 0, FN: 925, TP: 0, precision: 0, recall: 0.0, f1: 0 \n",
      "\n",
      "\n",
      "Epoch: 3\n",
      "\n",
      "a_CM: TN: 1022, FP: 104, FN: 818, TP: 56, precision: 35.0, recall: 6.41, f1: 10.84 \n",
      "\n",
      "\n",
      "b_CM: TN: 1075, FP: 0, FN: 925, TP: 0, precision: 0, recall: 0.0, f1: 0 \n",
      "\n",
      "\n",
      "Epoch: 4\n",
      "\n",
      "a_CM: TN: 1045, FP: 81, FN: 803, TP: 71, precision: 46.71, recall: 8.12, f1: 13.83 \n",
      "\n",
      "\n",
      "b_CM: TN: 1075, FP: 0, FN: 925, TP: 0, precision: 0, recall: 0.0, f1: 0 \n",
      "\n",
      "\n",
      "Epoch: 5\n",
      "\n",
      "a_CM: TN: 1034, FP: 92, FN: 817, TP: 57, precision: 38.26, recall: 6.52, f1: 11.14 \n",
      "\n",
      "\n",
      "b_CM: TN: 1075, FP: 0, FN: 925, TP: 0, precision: 0, recall: 0.0, f1: 0 \n",
      "\n",
      "\n",
      "Epoch: 6\n",
      "\n",
      "a_CM: TN: 1041, FP: 85, FN: 802, TP: 72, precision: 45.86, recall: 8.24, f1: 13.97 \n",
      "\n",
      "\n",
      "b_CM: TN: 1075, FP: 0, FN: 925, TP: 0, precision: 0, recall: 0.0, f1: 0 \n",
      "\n",
      "\n",
      "Epoch: 7\n",
      "\n",
      "a_CM: TN: 1042, FP: 84, FN: 816, TP: 58, precision: 40.85, recall: 6.64, f1: 11.42 \n",
      "\n",
      "\n",
      "b_CM: TN: 1075, FP: 0, FN: 925, TP: 0, precision: 0, recall: 0.0, f1: 0 \n",
      "\n",
      "\n",
      "Epoch: 8\n",
      "\n",
      "a_CM: TN: 1055, FP: 71, FN: 815, TP: 59, precision: 45.38, recall: 6.75, f1: 11.75 \n",
      "\n",
      "\n",
      "b_CM: TN: 1075, FP: 0, FN: 925, TP: 0, precision: 0, recall: 0.0, f1: 0 \n",
      "\n",
      "\n",
      "Epoch: 9\n",
      "\n",
      "a_CM: TN: 1041, FP: 85, FN: 814, TP: 60, precision: 41.38, recall: 6.86, f1: 11.77 \n",
      "\n",
      "\n",
      "b_CM: TN: 1075, FP: 0, FN: 925, TP: 0, precision: 0, recall: 0.0, f1: 0 \n",
      "\n",
      "\n",
      "Epoch: 10\n",
      "\n",
      "a_CM: TN: 1018, FP: 108, FN: 821, TP: 53, precision: 32.92, recall: 6.06, f1: 10.24 \n",
      "\n",
      "\n",
      "b_CM: TN: 1075, FP: 0, FN: 925, TP: 0, precision: 0, recall: 0.0, f1: 0 \n",
      "\n",
      "\n",
      "Epoch: 11\n",
      "\n",
      "a_CM: TN: 1042, FP: 84, FN: 805, TP: 69, precision: 45.1, recall: 7.89, f1: 13.43 \n",
      "\n",
      "\n",
      "b_CM: TN: 1075, FP: 0, FN: 925, TP: 0, precision: 0, recall: 0.0, f1: 0 \n",
      "\n",
      "\n",
      "Epoch: 12\n",
      "\n",
      "a_CM: TN: 1037, FP: 89, FN: 812, TP: 62, precision: 41.06, recall: 7.09, f1: 12.09 \n",
      "\n",
      "\n",
      "b_CM: TN: 1075, FP: 0, FN: 925, TP: 0, precision: 0, recall: 0.0, f1: 0 \n",
      "\n",
      "\n",
      "Epoch: 13\n",
      "\n",
      "a_CM: TN: 1048, FP: 78, FN: 804, TP: 70, precision: 47.3, recall: 8.01, f1: 13.7 \n",
      "\n",
      "\n",
      "b_CM: TN: 1075, FP: 0, FN: 925, TP: 0, precision: 0, recall: 0.0, f1: 0 \n",
      "\n",
      "\n",
      "Epoch: 14\n",
      "\n",
      "a_CM: TN: 1044, FP: 82, FN: 799, TP: 75, precision: 47.77, recall: 8.58, f1: 14.55 \n",
      "\n",
      "\n",
      "b_CM: TN: 1075, FP: 0, FN: 925, TP: 0, precision: 0, recall: 0.0, f1: 0 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "criterion = nn.MSELoss()\n",
    "b = nn.CrossEntropyLoss()\n",
    "lossfxn = nn.CrossEntropyLoss()\n",
    "\n",
    "# lossf = nn.MultiLabelMarginLoss()\n",
    "lossf = nn.MultiLabelMarginLoss() #nn.MultiLabelSoftMarginLoss()\n",
    "optimizer = optim.SGD(anmodel.parameters(), lr=0.1) # optim.SGD(anmodel.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "X = df_dev\n",
    "\n",
    "total_loss = 0\n",
    "total_hits = 0\n",
    "# Usually you want to pass over the training data several times.\n",
    "# 100 is much bigger than on a real data set, but real datasets have more than\n",
    "# two instances.  Usually, somewhere between 5 and 30 epochs is reasonable.\n",
    "for epoch in range(15):\n",
    "    print('Epoch: {0}\\n'.format(epoch))\n",
    "    a_conmat = ConfMatrix()\n",
    "    b_conmat = ConfMatrix()\n",
    "    for row in df_dev.loc[: , :].values:\n",
    "        txt = row[1] #row['Text']\n",
    "        pronoun = row[2] #row['Pronoun']\n",
    "        ca = row[4] #row['A']\n",
    "        cb = row[7]#row['B']\n",
    "        label = {}\n",
    "        label['A'] = row[6] #row['A-coref']\n",
    "        label['B'] = row[9] #row['B-coref']\n",
    "        \n",
    "        # Step 1. Remember that PyTorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        anmodel.zero_grad()\n",
    "\n",
    "        # Step 2. Make our BOW vector and also we must wrap the target in a\n",
    "        # Tensor as an integer. For example, if the target is SPANISH, then\n",
    "        # we wrap the integer 0. The loss function then knows that the 0th\n",
    "        # element of the log probabilities is the log probability\n",
    "        # corresponding to SPANISH\n",
    "        bow_vec = simple_tokenizer(txt, pronoun, ca, cb)\n",
    "        target = make_target(label, label_to_ix)\n",
    "        #print('target: ', target)\n",
    "        \n",
    "        \n",
    "        # Step 3. Run our forward pass.\n",
    "        log_probs = anmodel(bow_vec)\n",
    "        # Add row to confusion matrix\n",
    "        a_conmat.compare_row(log_probs[0][0].float(), target[0][0].float())\n",
    "        b_conmat.compare_row(log_probs[0][1].float(), target[0][1].float()) \n",
    "        \n",
    "        #print('prob: ', log_probs)\n",
    "        #print('log_probs', log_probs.view(2))\n",
    "        #print('target',target.view(2))\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        #lossf(x, y)\n",
    "        loss = lossf(log_probs, target)\n",
    "        #lossa = criterion(log_probs[0][0].float(), target[0][0].float()) \n",
    "        #lossb = criterion(log_probs[0][1].float(), target[0][1].float()) \n",
    "        # print('lossa: ',lossb, 'lossb: ',lossa,'\\n') \n",
    "        # outputs tensor(2.4402)\n",
    "        #loss = lossa + lossb\n",
    "        \n",
    "        #lossfxn(log_probs.view(2), target.view(2))\n",
    "         \n",
    "        \n",
    "       \n",
    "        #print('loss', loss,'\\n')\n",
    "       \n",
    "        # loss_a = a(log_probs[0], target[0])\n",
    "        #loss_b = b(log_probs[1], target[1])\n",
    "        #loss = loss_a + loss_b\n",
    "        # loss = loss_function(log_probs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('a_CM: {0}\\n'.format(a_conmat))\n",
    "    print('b_CM: {0}\\n'.format(b_conmat))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TN: 1075, FP: 0, FN: 925, TP: 0, precision: 0, recall: 0.0, f1: 0 "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_conmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss 0\n",
      "\n",
      "total_hits 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('total_loss {0}\\n'.format(total_loss))\n",
    "print('total_hits {0}\\n'.format(total_hits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Arbuzik/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:36: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_CM: TN: 246, FP: 21, FN: 173, TP: 14, precision: 40.0, recall: 7.49, f1: 12.62 \n",
      "\n",
      "\n",
      "b_CM: TN: 249, FP: 0, FN: 205, TP: 0, precision: 0, recall: 0.0, f1: 0 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    loss_val_total = 0\n",
    "    print('Validate\\n')\n",
    "    a_conmat = ConfMatrix()\n",
    "    b_conmat = ConfMatrix()\n",
    "    for row in df_val.loc[: , :].values:\n",
    "        txt = row[1] #row['Text']\n",
    "        pronoun = row[2] #row['Pronoun']\n",
    "        ca = row[4] #row['A']\n",
    "        cb = row[7]#row['B']\n",
    "        label = {}\n",
    "        #label = pd.DataFrame()\n",
    "        label['A'] = row[6] #row['A-coref']\n",
    "        label['B'] = row[9] #row['B-coref']\n",
    "        \n",
    "        target = make_target(label, label_to_ix)\n",
    "        \n",
    "        bow_vec = simple_tokenizer(txt, pronoun, ca, cb)\n",
    "        log_probs = anmodel(bow_vec)\n",
    "        a_conmat.compare_row(log_probs[0][0].float(), target[0][0].float())\n",
    "        b_conmat.compare_row(log_probs[0][1].float(), target[0][1].float()) \n",
    "        \n",
    "        \n",
    "        '''\n",
    "        loss = lossf(log_probs, target)\n",
    "        loss_val_total += loss.item()\n",
    "        print('pronoun',pronoun,\n",
    "              log_probs[0][0],\n",
    "              log_probs[0][1],\n",
    "              int(log_probs[0][0]),\n",
    "              'word 1',en_model.index2word[int(log_probs[0][0])],\n",
    "              '\\nword 2',en_model.index2word[int(log_probs[0][1])]\n",
    "             )\n",
    "        '''\n",
    "        \n",
    "        # print(log_probs,'\\n')\n",
    "    print('a_CM: {0}\\n'.format(a_conmat))\n",
    "    print('b_CM: {0}\\n'.format(b_conmat))\n",
    "    #print('total loss: ', loss_val_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>A</th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B</th>\n",
       "      <th>B-coref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He admitted making four trips to China and pla...</td>\n",
       "      <td>Jose de Venecia Jr</td>\n",
       "      <td>False</td>\n",
       "      <td>Abalos</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kathleen Nott was born in Camberwell, London. ...</td>\n",
       "      <td>Ellen</td>\n",
       "      <td>False</td>\n",
       "      <td>Kathleen</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When she returns to her hotel room, a Liberian...</td>\n",
       "      <td>Jason Scott Lee</td>\n",
       "      <td>False</td>\n",
       "      <td>Danny</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On 19 March 2007, during a campaign appearance...</td>\n",
       "      <td>Reucassel</td>\n",
       "      <td>True</td>\n",
       "      <td>Debnam</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>By this time, Karen Blixen had separated from ...</td>\n",
       "      <td>Finch Hatton</td>\n",
       "      <td>False</td>\n",
       "      <td>Beryl Markham</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>No amount of logic can shatter a faith conscio...</td>\n",
       "      <td>James Randi</td>\n",
       "      <td>False</td>\n",
       "      <td>Jos* Alvarez</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lieutenant General Weber Pasha wanted Faik Pas...</td>\n",
       "      <td>von Sanders</td>\n",
       "      <td>False</td>\n",
       "      <td>Faik Pasha</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>He went on to enter mainstream journalism as a...</td>\n",
       "      <td>Colin</td>\n",
       "      <td>False</td>\n",
       "      <td>Jake Burns</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>In 1940 Lester Cowan, an independent film prod...</td>\n",
       "      <td>Scott</td>\n",
       "      <td>False</td>\n",
       "      <td>Cowan</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>They have a stormy marriage, caused by his hot...</td>\n",
       "      <td>Beverley Callard</td>\n",
       "      <td>True</td>\n",
       "      <td>Liz</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>This particular government recalled all the Gr...</td>\n",
       "      <td>Ioannis Mamouris</td>\n",
       "      <td>False</td>\n",
       "      <td>Kallergis</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Nicole flirts with Charlie and gives him her p...</td>\n",
       "      <td>Nicole</td>\n",
       "      <td>True</td>\n",
       "      <td>Annie Sobacz</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>In the past,Princess Luminous is killed by Que...</td>\n",
       "      <td>Queen</td>\n",
       "      <td>True</td>\n",
       "      <td>Crystal</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>It's Always Fair Weather is a 1955 MGM musical...</td>\n",
       "      <td>Dan Dailey</td>\n",
       "      <td>False</td>\n",
       "      <td>Michael Kidd</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Aviation historian Phil Scott in The Shoulders...</td>\n",
       "      <td>Scott</td>\n",
       "      <td>False</td>\n",
       "      <td>Herring</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>In spite of this, ``Sullivan took (Wright) und...</td>\n",
       "      <td>Wright</td>\n",
       "      <td>True</td>\n",
       "      <td>Mueller</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text                   A  \\\n",
       "0   He admitted making four trips to China and pla...  Jose de Venecia Jr   \n",
       "1   Kathleen Nott was born in Camberwell, London. ...               Ellen   \n",
       "2   When she returns to her hotel room, a Liberian...     Jason Scott Lee   \n",
       "3   On 19 March 2007, during a campaign appearance...           Reucassel   \n",
       "4   By this time, Karen Blixen had separated from ...        Finch Hatton   \n",
       "5   No amount of logic can shatter a faith conscio...         James Randi   \n",
       "6   Lieutenant General Weber Pasha wanted Faik Pas...         von Sanders   \n",
       "7   He went on to enter mainstream journalism as a...               Colin   \n",
       "8   In 1940 Lester Cowan, an independent film prod...               Scott   \n",
       "9   They have a stormy marriage, caused by his hot...    Beverley Callard   \n",
       "10  This particular government recalled all the Gr...    Ioannis Mamouris   \n",
       "11  Nicole flirts with Charlie and gives him her p...              Nicole   \n",
       "12  In the past,Princess Luminous is killed by Que...               Queen   \n",
       "13  It's Always Fair Weather is a 1955 MGM musical...          Dan Dailey   \n",
       "14  Aviation historian Phil Scott in The Shoulders...               Scott   \n",
       "15  In spite of this, ``Sullivan took (Wright) und...              Wright   \n",
       "\n",
       "    A-coref              B  B-coref  \n",
       "0     False         Abalos    False  \n",
       "1     False       Kathleen     True  \n",
       "2     False          Danny     True  \n",
       "3      True         Debnam    False  \n",
       "4     False  Beryl Markham     True  \n",
       "5     False   Jos* Alvarez     True  \n",
       "6     False     Faik Pasha     True  \n",
       "7     False     Jake Burns     True  \n",
       "8     False          Cowan     True  \n",
       "9      True            Liz    False  \n",
       "10    False      Kallergis     True  \n",
       "11     True   Annie Sobacz    False  \n",
       "12     True        Crystal    False  \n",
       "13    False   Michael Kidd     True  \n",
       "14    False        Herring     True  \n",
       "15     True        Mueller    False  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.loc[:15 , ['Text', 'A', 'A-coref', 'B', 'B-coref']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
